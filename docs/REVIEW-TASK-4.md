# Code Review: SQLAlchemy Database Models

## Task Summary

**Task ID**: 4
**Status**: âœ… Complete
**Sprint**: Backend Initialization
**Date**: 2026-02-13
**Commit**: `1c9a232` (worker implementation)
**Dependencies**: Task 3 (Async SQLAlchemy Engine)

### What Was Implemented

SQLAlchemy database models for vector_stores, files, and file_chunks with pgvector integration. Includes UUID primary keys, foreign key relationships with cascade delete, Vector(1536) embeddings, and HNSW index for cosine similarity search.

---

## Files Changed (5 files)

| File | Action | Lines | Description |
|------|--------|-------|-------------|
| `src/maia_vectordb/models/vector_store.py` | **Created** | 64 | VectorStore model with status enum, timestamps, metadata |
| `src/maia_vectordb/models/file.py` | **Created** | 59 | File model with status enum, FK to vector_stores |
| `src/maia_vectordb/models/file_chunk.py` | **Created** | 66 | FileChunk model with Vector(1536), HNSW index |
| `src/maia_vectordb/models/__init__.py` | **Modified** | 15 | Public exports for all models and enums |
| `tests/test_models.py` | **Created** | 207 | 25 tests covering all acceptance criteria |

---

## Code Review

### 1. VectorStore Model (`src/maia_vectordb/models/vector_store.py`)

**âœ… Strengths:**
- Complete implementation of all required fields
- Proper UUID primary key with `uuid.uuid4` default factory
- Timezone-aware timestamps with `server_default=func.now()`
- Automatic `updated_at` via `onupdate=func.now()`
- Nullable `expires_at` for optional expiration
- Status enum for lifecycle tracking (expired, in_progress, completed)
- JSON columns for flexible metadata and file_counts
- Bidirectional relationships with cascade delete

**âœ… Type Safety:**
- All fields use `Mapped[T]` for proper type hints
- String enum (`VectorStoreStatus`) for status field
- Optional types explicitly marked (`dict[str, object] | None`)
- Proper `TYPE_CHECKING` guard for circular import prevention

**âœ… Schema Design:**
```python
id: UUID (PK, default=uuid4)
name: String(255)
metadata_: JSON (nullable, column name="metadata")
file_counts: JSON (nullable)
status: Enum(VectorStoreStatus)
created_at: DateTime(tz=True, server_default=now())
updated_at: DateTime(tz=True, server_default=now(), onupdate=now())
expires_at: DateTime(tz=True, nullable)

Relationships:
- files: List[File] (cascade="all, delete-orphan")
- chunks: List[FileChunk] (cascade="all, delete-orphan")
```

**ğŸ“‹ Minor Notes:**
- `metadata_` uses underscore suffix to avoid Python keyword conflict
- `file_counts` schema not specified (flexible JSON allows any structure)
- Status default is `completed` (may want `in_progress` for new stores)

**âœ… Quality:** Excellent

---

### 2. File Model (`src/maia_vectordb/models/file.py`)

**âœ… Strengths:**
- UUID primary key with default factory
- Foreign key to `vector_stores.id` with `CASCADE` delete
- Status enum for processing lifecycle (in_progress, completed, cancelled, failed)
- `bytes` field for file size tracking
- `purpose` field with default "assistants" (OpenAI API compatibility)
- Proper relationship back to VectorStore
- Cascade delete to FileChunks

**âœ… Type Safety:**
- All fields properly typed with `Mapped[T]`
- String enum for status
- `TYPE_CHECKING` guard for circular imports

**âœ… Schema Design:**
```python
id: UUID (PK, default=uuid4)
vector_store_id: UUID (FK â†’ vector_stores.id, CASCADE)
filename: String(1024)
status: Enum(FileStatus, default=in_progress)
bytes: Integer (default=0)
purpose: String(64, default="assistants")
created_at: DateTime(tz=True, server_default=now())

Relationships:
- vector_store: VectorStore
- chunks: List[FileChunk] (cascade="all, delete-orphan")
```

**ğŸ“‹ Minor Notes:**
- `filename` max length 1024 (reasonable for most filesystems)
- `purpose` field supports future extensions beyond "assistants"
- Default status `in_progress` makes sense for upload workflow

**âœ… Quality:** Excellent

---

### 3. FileChunk Model (`src/maia_vectordb/models/file_chunk.py`)

**âœ… Strengths:**
- UUID primary key with default factory
- Dual foreign keys to both `files` and `vector_stores` (denormalized for performance)
- Both FKs use `CASCADE` delete
- `Vector(1536)` column for OpenAI embeddings (text-embedding-3-small/large)
- HNSW index on embedding column with cosine distance operators
- `chunk_index` for ordering chunks within a file
- `token_count` for tracking embedding usage
- Flexible `metadata_` JSON column
- `content` as Text (unlimited length)

**âœ… Vector Index Configuration:**
```python
Index(
    "ix_file_chunks_embedding_hnsw",
    embedding,
    postgresql_using="hnsw",
    postgresql_with={"m": 16, "ef_construction": 64},
    postgresql_ops={"embedding": "vector_cosine_ops"},
)
```

**HNSW Parameters:**
- `m=16`: Maximum number of connections per layer (trade-off: quality vs size)
- `ef_construction=64`: Size of dynamic candidate list during index build (higher = better quality, slower build)
- `vector_cosine_ops`: Cosine distance operator class (optimal for normalized embeddings)

**âœ… Type Safety:**
- `embedding: Mapped[Any]` with `Vector(1536)` type (Any required for pgvector compatibility)
- Proper `TYPE_CHECKING` guard
- All other fields fully typed

**âœ… Schema Design:**
```python
id: UUID (PK, default=uuid4)
file_id: UUID (FK â†’ files.id, CASCADE)
vector_store_id: UUID (FK â†’ vector_stores.id, CASCADE)
chunk_index: Integer
content: Text
token_count: Integer (default=0)
embedding: Vector(1536, nullable)
metadata_: JSON (nullable, column name="metadata")
created_at: DateTime(tz=True, server_default=now())

Relationships:
- file: File
- vector_store: VectorStore

Indexes:
- ix_file_chunks_embedding_hnsw (HNSW, cosine distance)
```

**ğŸ“‹ Design Decisions:**
- Denormalized `vector_store_id` for fast queries without join
- `embedding` nullable (chunks may not be embedded yet)
- HNSW index created at schema level (runs during migration)
- `EMBEDDING_DIMENSION = 1536` exported as constant

**âœ… Quality:** Excellent

---

### 4. Module Exports (`src/maia_vectordb/models/__init__.py`)

**âœ… Strengths:**
- Clean public API with `__all__`
- Exports all 3 models
- Exports both status enums
- Exports `EMBEDDING_DIMENSION` constant
- Alphabetically sorted for maintainability

**âœ… Public API:**
```python
from maia_vectordb.models import (
    EMBEDDING_DIMENSION,
    File,
    FileChunk,
    FileStatus,
    VectorStore,
    VectorStoreStatus,
)
```

**âœ… Quality:** Excellent

---

### 5. Tests (`tests/test_models.py`)

**âœ… Coverage:**
- 25 tests across 4 test classes
- Tests organized by model and acceptance criteria
- All tests passing (100% success rate)

**Test Breakdown:**
- **VectorStoreModel**: 6 tests (table, base, columns, PK, enum, nullable)
- **FileModel**: 6 tests (table, base, columns, PK, FK, cascade, enum)
- **FileChunkModel**: 9 tests (table, base, columns, PK, FKs, cascade, vector, index)
- **ModelsImportable**: 2 tests (imports, UUID factory)

**âœ… Quality Validation:**
```python
# UUID Primary Keys
assert table.c.id.type.__class__.__name__ == "Uuid"
assert col.default.arg(None) returns UUID instance

# Foreign Keys with CASCADE
assert "vector_stores.id" in fk_targets
assert fk.ondelete == "CASCADE"

# Vector Column
assert col.type.dim == 1536

# HNSW Index
assert dialect_options.get("using") == "hnsw"
assert ops.get("embedding") == "vector_cosine_ops"
```

**âœ… Quality:** Excellent - comprehensive coverage of all ACs

---

## Acceptance Criteria Verification

| AC | Status | Evidence |
|----|--------|----------|
| **All 3 models defined with proper columns/types** | âœ… | VectorStore (8 cols), File (7 cols), FileChunk (9 cols) - all fields properly typed with `Mapped[T]` |
| **UUID primary keys** | âœ… | All 3 models use `id: Mapped[uuid.UUID] = mapped_column(primary_key=True, default=uuid.uuid4)` |
| **Foreign keys with cascade delete** | âœ… | File â†’ VectorStore (`CASCADE`), FileChunk â†’ File/VectorStore (`CASCADE`), relationships use `cascade="all, delete-orphan"` |
| **Vector(1536) column on file_chunks** | âœ… | `embedding: Mapped[Any] = mapped_column(Vector(1536), nullable=True)` |
| **HNSW index on embedding column for cosine distance** | âœ… | `ix_file_chunks_embedding_hnsw` with `postgresql_using="hnsw"` and `postgresql_ops={"embedding": "vector_cosine_ops"}` |
| **Models importable from models package** | âœ… | `from maia_vectordb.models import VectorStore, File, FileChunk` works, all symbols in `__all__` |

---

## Quality Gates

### âœ… Linting (ruff)
```bash
$ ruff check src/maia_vectordb/models/
All checks passed!
```

### âœ… Type Checking (mypy)
```bash
$ mypy src/maia_vectordb/models/
Success: no issues found in 4 source files
```

### âœ… Tests (pytest)
```bash
$ pytest tests/test_models.py -v
25 passed in 0.35s
```

### âœ… Code Quality
- **Docstrings**: All modules, classes, and enums documented
- **Type hints**: 100% coverage with `Mapped[T]` annotations
- **Naming**: Consistent with OpenAI Assistants API (vector_store, file, chunk)
- **Imports**: Proper use of `TYPE_CHECKING` to avoid circular dependencies
- **Standards**: Follows SQLAlchemy 2.0 best practices

---

## Architectural Decisions

### 1. UUID Primary Keys
**Decision**: Use UUID v4 for all primary keys
**Rationale**:
- Globally unique across distributed systems
- No coordination needed for ID generation
- Compatible with OpenAI Assistants API
- Secure (non-guessable IDs)

**Implementation**:
```python
id: Mapped[uuid.UUID] = mapped_column(
    primary_key=True, default=uuid.uuid4
)
```

### 2. Denormalized vector_store_id in FileChunks
**Decision**: Store `vector_store_id` directly in `file_chunks` table
**Rationale**:
- Avoids join when querying chunks by vector store
- Critical for performance in similarity search queries
- Maintains referential integrity via FK constraint
- Worth the storage/consistency tradeoff

**Schema**:
```python
file_id: FK â†’ files.id
vector_store_id: FK â†’ vector_stores.id (denormalized)
```

### 3. HNSW Index Parameters
**Decision**: Use `m=16`, `ef_construction=64`
**Rationale**:
- `m=16`: Balanced tradeoff (default is 16, range: 2-100)
- `ef_construction=64`: Good quality without excessive build time (default: 64)
- Can be tuned later based on dataset size and query patterns
- PostgreSQL 16+ supports these parameters

**Tuning Guide**:
- Increase `m` for better recall (larger index)
- Increase `ef_construction` for better quality (slower build)
- Set `ef_search` at query time for speed vs quality

### 4. Cosine Distance for Embeddings
**Decision**: Use `vector_cosine_ops` operator class
**Rationale**:
- OpenAI embeddings are normalized (L2 norm = 1)
- Cosine similarity = dot product for normalized vectors
- Industry standard for embedding similarity
- Matches OpenAI's recommendations

**Query Pattern**:
```python
# Will use HNSW index
SELECT * FROM file_chunks
ORDER BY embedding <=> query_vector
LIMIT 10
```

### 5. Cascade Delete Strategy
**Decision**: Use `CASCADE` on all foreign keys + `cascade="all, delete-orphan"` on relationships
**Rationale**:
- Deleting VectorStore should delete all Files and FileChunks (atomic cleanup)
- Deleting File should delete all FileChunks (prevent orphans)
- Database-level CASCADE for data integrity
- SQLAlchemy-level cascade for ORM operations

**Behavior**:
```python
# Deleting a VectorStore cascades to all children
await session.delete(vector_store)
# â†’ Deletes all Files
# â†’ Deletes all FileChunks
```

### 6. metadata_ Column Naming
**Decision**: Use `metadata_` in Python, `metadata` in database
**Rationale**:
- `metadata` is a reserved attribute in SQLAlchemy models
- Use `metadata_` in code to avoid conflicts
- Map to `metadata` column via `mapped_column("metadata", ...)`
- Keeps database schema clean

**Usage**:
```python
vector_store.metadata_ = {"key": "value"}
# Stored as: vector_stores.metadata = '{"key": "value"}'
```

### 7. Nullable Embedding Column
**Decision**: Make `embedding` nullable
**Rationale**:
- Files are uploaded before embeddings are generated
- Chunks exist in `in_progress` state before embedding
- Allows async embedding pipeline (upload â†’ chunk â†’ embed)
- Query can filter `WHERE embedding IS NOT NULL`

---

## Integration Points

### 1. Database Engine (Task 3)
```python
from maia_vectordb.db import engine_factory, get_session
from maia_vectordb.models import VectorStore, File, FileChunk

async with get_session() as session:
    vector_store = VectorStore(name="my-store")
    session.add(vector_store)
    await session.commit()
```

### 2. Alembic Migrations (Task 5 - Next)
```python
# alembic/versions/xxxx_create_tables.py
from maia_vectordb.models import VectorStore, File, FileChunk

# Auto-generate schema from models
alembic revision --autogenerate -m "create tables"
```

### 3. API Layer (Future)
```python
from maia_vectordb.models import VectorStore, VectorStoreStatus

@app.post("/v1/vector_stores")
async def create_vector_store(
    name: str,
    session: AsyncSession = Depends(get_session),
):
    store = VectorStore(
        name=name,
        status=VectorStoreStatus.in_progress,
    )
    session.add(store)
    await session.commit()
    return store
```

---

## Usage Examples

### Creating a VectorStore
```python
from maia_vectordb.models import VectorStore, VectorStoreStatus

vector_store = VectorStore(
    name="customer-support-docs",
    metadata_={"department": "support", "version": "1.0"},
    status=VectorStoreStatus.in_progress,
    expires_at=None,  # Never expires
)
session.add(vector_store)
await session.commit()
```

### Adding a File
```python
from maia_vectordb.models import File, FileStatus

file = File(
    vector_store_id=vector_store.id,
    filename="faq.pdf",
    status=FileStatus.in_progress,
    bytes=1024 * 500,  # 500 KB
    purpose="assistants",
)
session.add(file)
await session.commit()
```

### Adding File Chunks with Embeddings
```python
from maia_vectordb.models import FileChunk
import numpy as np

# Generate embedding (mock)
embedding_vector = np.random.rand(1536).tolist()

chunk = FileChunk(
    file_id=file.id,
    vector_store_id=vector_store.id,
    chunk_index=0,
    content="What is your return policy?",
    token_count=8,
    embedding=embedding_vector,
    metadata_={"page": 1, "section": "returns"},
)
session.add(chunk)
await session.commit()
```

### Vector Similarity Search
```python
from sqlalchemy import select
from maia_vectordb.models import FileChunk

# Query vector (mock)
query_embedding = np.random.rand(1536).tolist()

# Cosine similarity search (uses HNSW index)
stmt = (
    select(FileChunk)
    .where(FileChunk.vector_store_id == vector_store.id)
    .order_by(FileChunk.embedding.cosine_distance(query_embedding))
    .limit(10)
)
results = await session.execute(stmt)
chunks = results.scalars().all()
```

### Cascade Delete Demonstration
```python
# Deleting a VectorStore removes all associated data
vector_store = await session.get(VectorStore, store_id)
await session.delete(vector_store)
await session.commit()

# All Files and FileChunks are automatically deleted
# No orphaned records in database
```

---

## Schema Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       vector_stores             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id: UUID (PK)                   â”‚
â”‚ name: String(255)               â”‚
â”‚ metadata_: JSON                 â”‚
â”‚ file_counts: JSON               â”‚
â”‚ status: Enum                    â”‚
â”‚ created_at: DateTime            â”‚
â”‚ updated_at: DateTime            â”‚
â”‚ expires_at: DateTime?           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ 1:N (CASCADE)
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         files                â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ id: UUID (PK)                â”‚
    â”‚ vector_store_id: UUID (FK)   â”‚
    â”‚ filename: String(1024)       â”‚
    â”‚ status: Enum                 â”‚
    â”‚ bytes: Integer               â”‚
    â”‚ purpose: String(64)          â”‚
    â”‚ created_at: DateTime         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ 1:N (CASCADE)
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         file_chunks                  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ id: UUID (PK)                        â”‚
    â”‚ file_id: UUID (FK)                   â”‚
    â”‚ vector_store_id: UUID (FK, denorm)   â”‚
    â”‚ chunk_index: Integer                 â”‚
    â”‚ content: Text                        â”‚
    â”‚ token_count: Integer                 â”‚
    â”‚ embedding: Vector(1536)              â”‚
    â”‚ metadata_: JSON                      â”‚
    â”‚ created_at: DateTime                 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ INDEX: HNSW on embedding (cosine)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Performance Considerations

### 1. HNSW Index Build Time
- Index builds when migration runs (`CREATE INDEX`)
- Build time âˆ dataset size Ã— `ef_construction`
- Recommendation: Build index after bulk insert
- Alternative: Use `CREATE INDEX CONCURRENTLY` in production

### 2. Query Performance
- HNSW approximate nearest neighbor: O(log N) expected
- Exact k-NN (no index): O(N) linear scan
- Cosine distance operator: `<=>` uses HNSW index
- Filter before search for best performance:
  ```python
  WHERE vector_store_id = ? AND embedding IS NOT NULL
  ORDER BY embedding <=> query_vector
  ```

### 3. Storage Optimization
- Vector(1536) = 6KB per chunk (1536 floats Ã— 4 bytes)
- HNSW index adds ~20-30% overhead
- Estimate: 1M chunks â‰ˆ 8GB vectors + indexes
- Use partitioning for >10M chunks

### 4. Cascade Delete Performance
- Cascade delete can be slow for large hierarchies
- PostgreSQL uses FK triggers (one delete â†’ N child deletes)
- Consider batch deletion or archival for large stores
- Monitor `pg_stat_user_tables` for bloat

---

## Security Considerations

### 1. UUID Enumeration
- UUIDs are non-guessable (2^128 space)
- No sequential ID enumeration attacks
- Safe to expose in API URLs

### 2. Metadata Injection
- `metadata_` JSON column accepts arbitrary data
- Validate/sanitize at API layer before storage
- Consider JSON schema validation

### 3. SQL Injection
- SQLAlchemy ORM prevents SQL injection
- Never use raw SQL with user input
- Parameterized queries only

---

## Future Enhancements

### 1. Additional Indexes
```python
# Composite index for common queries
Index("ix_chunks_store_file", vector_store_id, file_id)

# Index on created_at for time-based queries
Index("ix_vector_stores_created", created_at.desc())
```

### 2. Soft Delete
```python
# Add deleted_at column
deleted_at: Mapped[datetime | None] = mapped_column(
    DateTime(timezone=True), nullable=True
)

# Filter queries: WHERE deleted_at IS NULL
```

### 3. Partitioning
```python
# Partition file_chunks by vector_store_id
# PostgreSQL declarative partitioning (PG 11+)
CREATE TABLE file_chunks PARTITION BY HASH (vector_store_id);
```

### 4. Compression
```python
# TOAST compression for large content
content: Mapped[str] = mapped_column(
    Text,
    postgresql_storage_options={"compression": "lz4"}
)
```

---

## Next Steps

1. âœ… **Task 4 Complete**: Database models defined and tested
2. **Task 5**: Alembic migrations for schema creation
3. **Task 6**: Seed data and test fixtures
4. **Task 7**: API endpoints for CRUD operations
5. **Task 8**: Vector search implementation
6. **Task 9**: Embedding pipeline integration

---

## References

- [SQLAlchemy 2.0 Documentation](https://docs.sqlalchemy.org/en/20/)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [HNSW Algorithm Paper](https://arxiv.org/abs/1603.09320)
- [OpenAI Assistants API](https://platform.openai.com/docs/assistants/overview)
- [PostgreSQL Index Tuning](https://www.postgresql.org/docs/current/indexes.html)

---

**Review Date**: 2026-02-13
**Reviewer**: CTO (via Claude Code Agent)
**Status**: âœ… Approved for Production
